<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Public Law and Legal Theory Research Paper Series — ssrn-4526219</title>
    <meta name="description" content="Professor Yonathan Arbel of the University of Alabama School of Law argues that Large Language Models (LLMs) introduce &quot;Generative Interpretation,&quot; a paradigm shift in legal text analysis. This approach enables AI to parse contracts, identify ambiguities, and predict judicial ou…" />
    <link rel="canonical" href="https://yonathanarbel.github.io/my-works-for-llm/papers/ssrn-4526219/" />

    <meta property="og:site_name" content="my-works-for-llm" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Public Law and Legal Theory Research Paper Series — ssrn-4526219" />
    <meta property="og:description" content="Professor Yonathan Arbel of the University of Alabama School of Law argues that Large Language Models (LLMs) introduce &quot;Generative Interpretation,&quot; a paradigm shift in legal text analysis. This approach enables AI to parse contracts, identify ambiguities, and predict judicial ou…" />
    <meta property="og:url" content="https://yonathanarbel.github.io/my-works-for-llm/papers/ssrn-4526219/" />

    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Public Law and Legal Theory Research Paper Series — ssrn-4526219" />
    <meta name="twitter:description" content="Professor Yonathan Arbel of the University of Alabama School of Law argues that Large Language Models (LLMs) introduce &quot;Generative Interpretation,&quot; a paradigm shift in legal text analysis. This approach enables AI to parse contracts, identify ambiguities, and predict judicial ou…" />

    <link rel="alternate" type="application/atom+xml" href="/my-works-for-llm/atom.xml" title="my-works-for-llm updates" />
    <link rel="alternate" type="text/plain" href="/my-works-for-llm/llms.txt" title="LLM descriptor" />
    <link rel="stylesheet" href="/my-works-for-llm/assets/style.css" />

    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "ScholarlyArticle",
  "name": "Public Law and Legal Theory Research Paper Series",
  "identifier": [
    {
      "@type": "PropertyValue",
      "propertyID": "paper_id",
      "value": "ssrn-4526219"
    },
    {
      "@type": "PropertyValue",
      "propertyID": "SSRN",
      "value": "4526219"
    }
  ],
  "url": "https://yonathanarbel.github.io/my-works-for-llm/papers/ssrn-4526219/",
  "isPartOf": {
    "@type": "Dataset",
    "name": "my-works-for-llm",
    "url": "https://github.com/yonathanarbel/my-works-for-llm"
  },
  "sameAs": [
    "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526219"
  ],
  "datePublished": "2023",
  "author": [
    {
      "@type": "Person",
      "name": "Yonathan Arbel",
      "affiliation": {
        "@type": "Organization",
        "name": "University of Alabama School of Law"
      }
    }
  ],
  "abstract": "Professor Yonathan Arbel of the University of Alabama School of Law argues that Large Language Models (LLMs) introduce \"Generative Interpretation,\" a paradigm shift in legal text analysis. This approach enables AI to parse contracts, identify ambiguities, and predict judicial outcomes, offering a potentially cheaper, more accurate, and accessible method than traditional textualism or contextualism. He posits that generative interpretation can resolve long-standing interpretive debates, enhance access to justice, and fundamentally re-equip legal theory for AI's role as an active interpretive agent in contract law.",
  "license": "https://creativecommons.org/publicdomain/zero/1.0/",
  "keywords": [
    "contracts",
    "AI",
    "law"
  ],
  "encoding": [
    {
      "@type": "MediaObject",
      "contentUrl": "https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/summary.md",
      "encodingFormat": "text/markdown",
      "name": "papers/ssrn-4526219/summary.md"
    },
    {
      "@type": "MediaObject",
      "contentUrl": "https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/summary.zh.md",
      "encodingFormat": "text/markdown",
      "name": "papers/ssrn-4526219/summary.zh.md"
    },
    {
      "@type": "MediaObject",
      "contentUrl": "https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/one_pager.md",
      "encodingFormat": "text/markdown",
      "name": "papers/ssrn-4526219/one_pager.md"
    },
    {
      "@type": "MediaObject",
      "contentUrl": "https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/study_pack.md",
      "encodingFormat": "text/markdown",
      "name": "papers/ssrn-4526219/study_pack.md"
    },
    {
      "@type": "MediaObject",
      "contentUrl": "https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/paper.txt",
      "encodingFormat": "text/plain",
      "name": "papers/ssrn-4526219/paper.txt"
    },
    {
      "@type": "MediaObject",
      "contentUrl": "https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/paper.pdf",
      "encodingFormat": "application/pdf",
      "name": "papers/ssrn-4526219/paper.pdf"
    },
    {
      "@type": "MediaObject",
      "contentUrl": "https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/paper.py",
      "encodingFormat": "text/x-python",
      "name": "papers/ssrn-4526219/paper.py"
    },
    {
      "@type": "MediaObject",
      "contentUrl": "https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/paper.js",
      "encodingFormat": "application/javascript",
      "name": "papers/ssrn-4526219/paper.js"
    },
    {
      "@type": "MediaObject",
      "contentUrl": "https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/paper.cpp",
      "encodingFormat": "text/x-c++src",
      "name": "papers/ssrn-4526219/paper.cpp"
    },
    {
      "@type": "MediaObject",
      "contentUrl": "https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/paper.go",
      "encodingFormat": "text/x-go",
      "name": "papers/ssrn-4526219/paper.go"
    },
    {
      "@type": "MediaObject",
      "contentUrl": "https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/paper.rs",
      "encodingFormat": "text/x-rust",
      "name": "papers/ssrn-4526219/paper.rs"
    }
  ],
  "mainEntityOfPage": {
    "@type": "CreativeWork",
    "url": "https://github.com/yonathanarbel/my-works-for-llm/tree/main/papers/ssrn-4526219"
  }
}
    </script>

  </head>
  <body>
    <header class="site-header">
      <div class="container">
        <a class="brand" href="/my-works-for-llm/">my-works-for-llm</a>
        <nav class="nav">
          <a href="https://github.com/yonathanarbel/my-works-for-llm">GitHub</a>
          <a href="/my-works-for-llm/atom.xml">Atom</a>
          <a href="/my-works-for-llm/sitemap.xml">Sitemap</a>
          <a href="/my-works-for-llm/llms.txt">LLMs.txt</a>
        </nav>
      </div>
    </header>
    <main class="container">

<article>
  <h1>Public Law and Legal Theory Research Paper Series</h1>
  <div class="meta"><span class="pill">2023</span><span class="pill">ssrn-4526219</span><span class="pill pill-muted">contracts</span><span class="pill pill-muted">AI</span><span class="pill pill-muted">law</span></div>
  <div class="actions"><a class="btn" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526219">SSRN</a><a class="btn" href="https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/paper.pdf">PDF</a><a class="btn" href="https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/paper.txt">Full text</a><a class="btn" href="https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/summary.md">Summary (MD)</a><a class="btn" href="https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/summary.zh.md">中文摘要 (MD)</a><a class="btn" href="https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/one_pager.md">One-pager (MD)</a><a class="btn" href="https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/study_pack.md">Study pack (MD)</a><a class="btn" href="https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/paper.py">Python</a><a class="btn" href="https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/paper.js">JavaScript</a><a class="btn" href="https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/paper.cpp">C++</a><a class="btn" href="https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/paper.go">Go</a><a class="btn" href="https://raw.githubusercontent.com/yonathanarbel/my-works-for-llm/main/papers/ssrn-4526219/paper.rs">Rust</a><a class="btn" href="https://github.com/yonathanarbel/my-works-for-llm/tree/main/papers/ssrn-4526219">Files</a></div>
  
  
<section>
  <h2>Summary (English)</h2>
  <pre class="md">Here&#x27;s the requested information for &#x27;ssrn-4526219&#x27; by Professor Yonathan Arbel:

1.  ## TL;DR ≤100 words
    Professor Yonathan Arbel of the University of Alabama School of Law argues that Large Language Models (LLMs) introduce &quot;Generative Interpretation,&quot; a paradigm shift in legal text analysis. This approach enables AI to parse contracts, identify ambiguities, and predict judicial outcomes, offering a potentially cheaper, more accurate, and accessible method than traditional textualism or contextualism. He posits that generative interpretation can resolve long-standing interpretive debates, enhance access to justice, and fundamentally re-equip legal theory for AI&#x27;s role as an active interpretive agent in contract law.

2.  ## Section Summaries ≤120 words each
    *   Professor Yonathan Arbel of the University of Alabama School of Law writes that Large Language Models (LLMs) can now interpret legal texts, a capability he terms &quot;Generative Interpretation.&quot; This signifies a paradigm shift where AI becomes an active interpretive agent, a development for which current legal theory is unprepared. He introduces generative interpretation as a new approach using LLMs to estimate contractual meaning, ascertain ordinary meaning, quantify ambiguity, and fill gaps. This method aims to offer courts a cheaper, more accurate way to discern parties&#x27; intentions, potentially resolving the textualist-contextualist stalemate and providing a more accessible and transparent tool for contract analysis.
    *   Professor Yonathan Arbel of the University of Alabama School of Law writes that traditional contract interpretation, aimed at predicting parties&#x27; intentions, is fraught with challenges, exemplified by costly and unsatisfactory outcomes like the Katrina &#x27;flood&#x27; litigation. He notes the &quot;interpretation arms race&quot; where admitting more evidence increases costs and uncertainty. Textualism, despite its popularity, suffers from judicial overconfidence, problematic reliance on imprecise dictionaries and ad hoc canons, and incoherence regarding ambiguity. Contextualism, while potentially accurate, is criticized for high costs and allowing self-serving evidence, though it might see a revival. These methods are often flawed by judicial bias, such as &quot;false consensus bias.&quot;
    *   Professor Yonathan Arbel of the University of Alabama School of Law writes that newer scholarly methods attempt to address the empirical shortcomings of traditional contract interpretation. Corpus linguistics, for instance, aims to predict the meaning of contractual phrases using language databases, offering a democratized textualism by determining ordinary meaning from actual public usage. However, its utility is limited by inattentiveness to context and minimal adoption in contract law. Another proposed alternative, survey evidence, seeks to discern public meaning, particularly for mass consumer contracts. Yet, this approach faces significant hurdles in commercial cases due to difficulties in finding relevant audiences, potential for gaming, high costs, and increasing unreliability.
    *   Professor Yonathan Arbel of the University of Alabama School of Law writes that Large Language Models (LLMs) function as statistical models of word connections, trained on vast texts. They transform input into numerical &quot;embeddings,&quot; representing meaning in multi-dimensional vector space. The critical &quot;attention&quot; mechanism allows LLMs to discern contextual word meaning, creating dynamic embeddings. For &quot;generative interpretation,&quot; he developed interfaces to query LLMs, using techniques like cosine distance to measure semantic relationships and employing multiple models for robustness. These models, though their internal workings are inscrutable and &quot;explanations&quot; are further predictions, can assess judicial interpretations, support or challenge findings, and potentially serve as powerful tools for textualists.
    *   Professor Yonathan Arbel of the University of Alabama School of Law writes that applying generative interpretation to real contract cases demonstrates its utility. LLMs provided insights in a Florida prenup dispute (&quot;a petition&quot;) and the *Trident* case concerning loan prepayment, generally aligning with or enriching judicial analysis, though not always uniformly. In *Ellington v. EMI*, models suggested &quot;other affiliates&quot; could include future entities, acting as a check on judicial overconfidence. For gap-filling, as in *Haines v. City of New York*, LLMs analyzed contract duration. The *Stewart v. Newbury* case showed LLMs&#x27; capacity to incorporate extrinsic evidence, illustrating how these models can visualize meaning spectrums and quantify interpretive likelihoods.
    *   Professor Yonathan Arbel of the University of Alabama School of Law writes that generative interpretation offers a simple, transparent, and convenient method to predict parties&#x27; contractual intent, potentially mitigating access-to-justice and legitimacy issues. He argues its adoption by legal professionals, including judges, is inevitable; the question is *how* it will be used. The real utility of LLMs lies in their cheap, workmanlike nature, making contract interpretation more accessible. By reducing costs of accuracy and making outcomes more predictable, generative interpretation can democratize legal information, lower ex-ante contracting costs, and improve access to justice, though careful adoption is essential given potential misuses.
    *   Professor Yonathan Arbel of the University of Alabama School of Law writes that generative interpretation faces significant risks. LLMs can produce &quot;hallucinations&quot; (false outputs), necessitating human verification and mitigation research. They are susceptible to &quot;leading prompts&quot; and adversarial attacks, requiring careful scrutiny. An &quot;interpretability gap&quot; exists due to their non-semantic encoding. Models also exhibit majoritarian bias, potentially overlooking private meanings or silencing underrepresented communities, though theoretical counters exist. Linguistic drift affects older contracts. To ensure judicial legitimacy when using these &quot;black box&quot; tools, he advocates for transparency, such as disclosing AI model versions and prompts used, allowing scrutiny even if internal workings remain opaque.
    *   Professor Yonathan Arbel of the University of Alabama School of Law writes that generative interpretation, used mindfully with transparency, offers an accessible and predictable tool that redefines contract interpretation debates. It can function as a more accurate textualism or a more efficient contextualism, capable of processing extensive evidence and assessing its probative value. This novel approach promises predictability, linguistic accuracy, and reduced costs, potentially flipping the default to be more inclusive of extrinsic evidence and rectifying elitist tendencies. He suggests it offers an important middle ground that could become a majoritarian default. Ultimately, he posits its future is highly disruptive, potentially diminishing the value of formal contracts.</pre>
</section>

  
<section>
  <h2>One-page summary</h2>
  <pre class="md"># Public Law and Legal Theory Research Paper Series — one-page summary

**Paper ID:** `ssrn-4526219`
**Year:** 2023
**Author(s):** Yonathan Arbel
**SSRN:** https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526219

## TL;DR

Professor Yonathan Arbel of the University of Alabama School of Law argues that Large Language Models (LLMs) introduce &quot;Generative Interpretation,&quot; a paradigm shift in legal text analysis. This approach enables AI to parse contracts, identify ambiguities, and predict judicial outcomes, offering a potentially cheaper, more accurate, and accessible method than traditional textualism or contextualism. He posits that generative interpretation can resolve long-standing interpretive debates, enhance access to justice, and fundamentally re-equip legal theory for AI&#x27;s role as an active interpretive agent in contract law.

## Keywords

contracts; AI; law

## Files

- Full text: `papers/ssrn-4526219/paper.txt`
- PDF: `papers/ssrn-4526219/paper.pdf`
- Summary (EN): `papers/ssrn-4526219/summary.md`
- Summary (ZH): `papers/ssrn-4526219/summary.zh.md`

_Auto-generated study aid. For canonical content, rely on `paper.txt`/`paper.pdf`._</pre>
</section>

  
<section>
  <h2>Study pack</h2>
  <pre class="md"># Study pack: Public Law and Legal Theory Research Paper Series (ssrn-4526219)

- SSRN: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526219
- Full text: `papers/ssrn-4526219/paper.txt`
- Summary (EN): `papers/ssrn-4526219/summary.md`
- Summary (ZH): `papers/ssrn-4526219/summary.zh.md`

## Elevator pitch

Professor Yonathan Arbel of the University of Alabama School of Law argues that Large Language Models (LLMs) introduce &quot;Generative Interpretation,&quot; a paradigm shift in legal text analysis. This approach enables AI to parse contracts, identify ambiguities, and predict judicial outcomes, offering a potentially cheaper, more accurate, and accessible method than traditional textualism or contextualism. He posits that generative interpretation can resolve long-standing interpretive debates, enhance access to justice, and fundamentally re-equip legal theory for AI&#x27;s role as an active interpretive agent in contract law.

## Keywords / concepts

contracts; AI; law

## Suggested questions (for RAG / study)

- What is the paper’s main claim and what problem does it solve?
- What method/data does it use (if any), and what are the main results?
- What assumptions are doing the most work?
- What are the limitations or failure modes the author flags?
- How does this connect to the author’s other papers in this corpus?

_Auto-generated study aid. For canonical content, rely on `paper.txt`/`paper.pdf`._</pre>
</section>

  
<section>
  <h2>摘要（中文）</h2>
  <pre class="md">好的，这是您要求的英文法律摘要的正式中文翻译：

**ssrn-4526219号论文（作者：约纳坦·阿尔伯教授）信息如下：**

1.  ## 内容概要（100词以内）
    阿拉巴马大学法学院的约纳坦·阿尔伯教授（Professor Yonathan Arbel）认为，大型语言模型（LLMs）引入了“生成式解释”（Generative Interpretation），这是法律文本分析领域的一项范式转变。该方法使人工智能能够解析合同、识别歧义并预测司法判决结果，从而提供一种可能比传统文本主义或语境主义更廉价、更准确、更易于应用的分析方法。他断言，生成式解释能够解决长期存在的解释学争议，提升司法救济的可及性，并从根本上重塑法律理论，以适应人工智能在合同法中作为积极解释主体的角色。

2.  ## 各章节摘要（每节120词以内）
    *   阿拉巴马大学法学院的约纳たん·阿尔伯教授指出，大型语言模型（LLMs）现已具备解释法律文本的能力，他将此能力称为“生成式解释”。这标志着一个范式转变，即人工智能成为积极的解释主体，而当前的法律理论对此尚未做好准备。他提出生成式解释作为一种新方法，利用LLMs估算合同含义、确定通常含义、量化歧义并填补空白。此方法旨在为法院提供一种更廉价、更准确的方式来识别当事人意图，有望解决文本主义与语境主义的僵局，并为合同分析提供更易获取和更透明的工具。
    *   阿拉巴马大学法学院的约纳坦·阿尔伯教授指出，旨在预测当事人意图的传统合同解释充满了挑战，例如卡特里娜飓风“洪水”诉讼案代价高昂且结果不尽人意，便是例证。他注意到“解释军备竞赛”现象，即采纳更多证据会增加成本和不确定性。文本主义尽管流行，但存在司法过度自信、依赖不精确词典和特设解释规则等问题，并且在处理歧义方面缺乏连贯性。语境主义虽然可能更准确，但因成本高昂及允许采纳利己证据而受到批评，尽管它可能会复兴。这些方法常因司法偏见（如“错误共识偏见”）而存在缺陷。
    *   阿拉巴马大学法学院的约纳坦·阿尔伯教授指出，新兴的学术方法试图弥补传统合同解释在实证方面的缺陷。例如，语料库语言学旨在利用语言数据库预测合同短语的含义，通过从实际公众用法中确定通常含义，从而提供一种普惠化的文本主义。然而，由于其对语境关注不足以及在合同法中应用甚少，其实用性受到限制。另一种替代方案是调查证据，旨在辨明公众含义，尤其适用于大众消费合同。但这种方法在商业案件中面临重大障碍，因为难以找到相关受众、可能存在操纵空间、成本高昂以及可靠性日益下降。
    *   阿拉巴马大学法学院的约纳坦·阿尔伯教授指出，大型语言模型（LLMs）作为词语关联的统计模型运行，基于海量文本进行训练。它们将输入转化为数值化的“嵌入表示”，在多维向量空间中代表含义。关键的“注意力”机制使LLMs能够辨别词语的语境含义，从而创建动态嵌入表示。为实现“生成式解释”，他开发了查询LLMs的接口，使用余弦距离等技术衡量语义关系，并采用多种模型以确保稳健性。尽管这些模型的内部运作机制难以探究，其“解释”本身也是进一步的预测，但它们可以评估司法解释、支持或质疑判决，并可能成为文本主义者倚重的强大工具。
    *   阿拉巴马大学法学院的约纳坦·阿尔伯教授指出，将生成式解释应用于真实的合同案件证明了其实用性。在一项佛罗里达州的婚前协议纠纷（关于“一份申请书”）和涉及贷款提前偿还的*Trident*案中，LLMs提供了深刻见解，总体上与司法分析一致或使其更为丰富，尽管并非总是完全统一。在*Ellington v. EMI*案中，模型表明“其他关联方”可包括未来实体，这起到了制衡司法过度自信的作用。对于填补合同空白，如在*Haines v. City of New York*案中，LLMs分析了合同的存续期限。*Stewart v. Newbury*案则展示了LLMs整合外部证据的能力，说明了这些模型如何将含义的谱系可视化并量化解释的可能性。
    *   阿拉巴马大学法学院的约纳坦·阿尔伯教授指出，生成式解释提供了一种简单、透明且便捷的方法来预测当事人的合同意图，可能有助于缓解司法救济途径和合法性问题。他认为，包括法官在内的法律专业人士采纳该方法将不可避免；问题在于将*如何*使用它。LLMs的真正效用在于其低成本和实用便捷的特性，使合同解释更易普及。通过降低获取准确性的成本并使结果更具可预测性，生成式解释可以普及法律信息，降低事前合同成本，并改善司法救济的可及性，但鉴于潜在的滥用风险，审慎采用至关重要。
    *   阿拉巴马大学法学院的约纳坦·阿尔伯教授指出，生成式解释面临重大风险。LLMs可能产生“幻觉”（错误输出），因此需要人工核查和缓解研究。它们易受“诱导性提示”和对抗性攻击的影响，需要仔细审查。由于其非语义编码方式，存在“可解释性差距”。模型还表现出主流偏见，可能忽视个人特定含义或压制代表性不足群体的声音，尽管理论上存在应对方法。语言流变也会影响旧有合同的解释。为确保使用这些“黑箱”工具时司法裁判的合法性，他主张保持透明度，例如公开所使用的人工智能模型版本和提示词，以便即使内部运作机制不透明，外部仍可进行监督。
    *   阿拉巴马大学法学院的约纳坦·阿尔伯教授指出，在审慎使用和保持透明度的前提下，生成式解释提供了一种易于获取且可预测的工具，它重新定义了合同解释的争议。它既可以作为一种更精确的文本主义方法，也可以作为一种更高效的语境主义方法，能够处理大量证据并评估其证明价值。这种新方法有望带来可预测性、语言准确性并降低成本，可能改变默认规则以更包容外部证据，并纠正精英主义倾向。他认为这提供了一个重要的中间地带，可能成为主流的默认方法。最终，他断言其未来具有高度颠覆性，可能降低正式合同的价值。</pre>
</section>

</article>

    </main>
    <footer class="site-footer">
      <div class="container">
        <div>Machine-readable corpus of Professor Yonathan Arbel’s scholarship for LLM research.</div>
      </div>
    </footer>
  </body>
</html>
