# How to Count AIs: Individuation and Liability for AI Agents

## TL;DR

AI agents can copy, split, merge, and disappear, which makes legal accountability hard because law must first identify which AI acted. The paper argues that governance needs two layers of AI identity: "thin" identity (linking AI actions to human principals) and "thick" identity (distinguishing AI agents as persistent actors with coherent goals). It proposes an "Algorithmic Corporation" (A-corp) framework to connect AI actions to human ownership while also creating stable, legally legible AI entities that can be governed directly through legal incentives.

## Abstract Snapshot

As AI agents become widespread, legal systems will need reliable methods to identify and distinguish them when harms occur. The article presents the identity problem and explains why human-only accountability is insufficient in many principal-agent settings. It then proposes A-corps as a legal structure intended to solve both attribution to humans and practical individuation of AI agents.