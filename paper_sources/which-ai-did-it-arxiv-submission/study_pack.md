# Study pack: How to Count AIs: Individuation and Liability for AI Agents (which-ai-did-it-arxiv-submission)

- Full text: `paper_sources/which-ai-did-it-arxiv-submission/paper.txt`
- Summary (EN): `paper_sources/which-ai-did-it-arxiv-submission/summary.md`

## Elevator pitch

AI agents can copy, split, merge, and disappear, which makes legal accountability hard because law must first identify which AI acted. The paper argues that governance needs two layers of AI identity: "thin" identity (linking AI actions to human principals) and "thick" identity (distinguishing AI agents as persistent actors with coherent goals). It proposes an "Algorithmic Corporation" (A-corp) framework to connect AI actions to human ownership while also creating stable, legally legible AI entities that can be governed directly through legal incentives.

## Keywords / concepts

AI agents; legal identity; individuation; liability

## Suggested questions (for RAG / study)

- What is the paper’s main claim and what problem does it solve?
- What method/data does it use (if any), and what are the main results?
- What assumptions are doing the most work?
- What are the limitations or failure modes the author flags?
- How does this connect to the author’s other papers in this corpus?

_Auto-generated study aid. For canonical content, rely on `paper.txt`/`paper.pdf`._
